# üñ•Ô∏è An√°lise de Viabilidade - GPU RTX 3050 6GB

## Especifica√ß√µes do Sistema

### GPU
- **Modelo:** NVIDIA GeForce RTX 3050 6GB Laptop GPU
- **Mem√≥ria VRAM:** 6 GB (6144 MiB)
- **Compute Capability:** 8.6 (Arquitetura Ampere)
- **Driver:** 535.274.02

### Sistema
- **RAM:** 21 GB total (~5 GB dispon√≠vel)
- **CPU:** 12 cores
- **Swap:** 5.6 GB

---

## ‚úÖ An√°lise por Componente do Pipeline

### 1. **Download e Prepara√ß√£o de Datasets** ‚úÖ
**Viabilidade:** ‚úÖ **SIM - Sem problemas**

- N√£o requer GPU
- Opera√ß√µes de I/O e descompacta√ß√£o
- RAM suficiente para processar arquivos

**Recomenda√ß√µes:**
- Processar datasets em lotes se necess√°rio
- Usar links simb√≥licos para economizar espa√ßo em disco

---

### 2. **Extra√ß√£o de Features** ‚ö†Ô∏è
**Viabilidade:** ‚ö†Ô∏è **SIM, mas com limita√ß√µes**

#### 2.1 Baseline CNN (ResNet50) ‚úÖ
- **Mem√≥ria necess√°ria:** ~2-3 GB VRAM
- **Batch size recomendado:** 16-32
- **Status:** ‚úÖ Funciona bem

#### 2.2 ViT Puro ‚úÖ
- **Mem√≥ria necess√°ria:** ~2-4 GB VRAM
- **Batch size recomendado:** 8-16 (dependendo do modelo)
- **Status:** ‚úÖ Funciona, mas com batches menores

#### 2.3 ViT + Contrastive (domain_specific_cl) ‚ö†Ô∏è
- **Mem√≥ria necess√°ria:** ~3-5 GB VRAM
- **Batch size recomendado:** 4-8
- **Status:** ‚ö†Ô∏è Funciona, mas pode ser lento
- **Nota:** Usa TensorFlow 1.x (pode ter problemas de compatibilidade)

#### 2.4 ViT + MIM (MIM-Med3D) ‚ö†Ô∏è
- **Mem√≥ria necess√°ria:** ~4-6 GB VRAM
- **Batch size recomendado:** 2-4 (dados 3D s√£o pesados)
- **Status:** ‚ö†Ô∏è **Limite da GPU - requer otimiza√ß√µes**
- **Dados 3D:** Volumes m√©dicos s√£o muito pesados para 6GB

#### 2.5 ViT + Sparse ‚úÖ
- **Mem√≥ria necess√°ria:** ~1-2 GB VRAM (apenas processamento CPU)
- **Status:** ‚úÖ Funciona sem problemas

**Recomenda√ß√µes para Extra√ß√£o:**
```python
# Ajustar batch sizes no notebook 02_Feature_Extraction.ipynb
BATCH_SIZES = {
    "baseline_cnn": 32,
    "vit_pure": 16,
    "vit_contrastive": 8,
    "vit_mim": 4,  # Reduzido para dados 3D
    "vit_sparse": 32
}
```

---

### 3. **Classifica√ß√£o (SVM e SRC)** ‚úÖ
**Viabilidade:** ‚úÖ **SIM - Sem problemas**

- **SVM:** Executa principalmente na CPU
- **SRC:** Executa principalmente na CPU
- **Mem√≥ria RAM:** Suficiente para datasets m√©dios

**Recomenda√ß√µes:**
- Usar `n_jobs=-1` para paralelizar no CPU
- Processar em chunks se o dataset for muito grande

---

### 4. **Avalia√ß√£o Estat√≠stica** ‚úÖ
**Viabilidade:** ‚úÖ **SIM - Sem problemas**

- Opera√ß√µes estat√≠sticas na CPU
- Visualiza√ß√µes leves
- Sem requisitos de GPU

---

## üéØ Resumo de Viabilidade

| Componente | Viabilidade | Batch Size Recomendado | Observa√ß√µes |
|-----------|-------------|----------------------|-------------|
| Download Datasets | ‚úÖ Excelente | N/A | Sem GPU necess√°ria |
| Baseline CNN | ‚úÖ Boa | 32 | Funciona bem |
| ViT Puro | ‚úÖ Boa | 16 | Funciona bem |
| ViT + Contrastive | ‚ö†Ô∏è Moderada | 8 | Pode ser lento |
| ViT + MIM | ‚ö†Ô∏è **Limitada** | **2-4** | **Limite da GPU** |
| ViT + Sparse | ‚úÖ Excelente | 32 | CPU apenas |
| Classifica√ß√£o | ‚úÖ Excelente | N/A | CPU apenas |
| Avalia√ß√£o Estat√≠stica | ‚úÖ Excelente | N/A | CPU apenas |

---

## ‚ö†Ô∏è Principais Desafios

### 1. **Mem√≥ria VRAM Limitada (6GB)**
- **Problema:** Dados m√©dicos 3D (BraTS, ACDC) s√£o volumosos
- **Solu√ß√£o:** 
  - Reduzir batch size para 2-4
  - Processar volumes em slices 2D
  - Usar mixed precision (j√° implementado)

### 2. **ViT + MIM (Dados 3D)**
- **Problema:** Modelos 3D consomem muita mem√≥ria
- **Solu√ß√£o:**
  - Processar apenas slices 2D dos volumes
  - Usar gradient checkpointing se dispon√≠vel
  - Considerar usar apenas dados 2D para este bra√ßo

### 3. **domain_specific_cl (TensorFlow 1.x)**
- **Problema:** Incompatibilidade com vers√µes modernas
- **Solu√ß√£o:**
  - Usar ambiente virtual separado
  - Ou usar fallback para ViT puro (j√° implementado)

---

## üöÄ Otimiza√ß√µes Recomendadas

### 1. **Mixed Precision** ‚úÖ (J√° implementado)
```python
# J√° est√° no c√≥digo
policy = tf.keras.mixed_precision.Policy('mixed_float16')
```

### 2. **Processamento em Slices 2D**
Para dados 3D, processar slice por slice:
```python
# Em vez de processar volume completo
for slice_idx in range(volume.shape[2]):
    slice_2d = volume[:, :, slice_idx]
    features = extract_features(slice_2d)
```

### 3. **Gradient Checkpointing**
Para modelos grandes:
```python
# Se dispon√≠vel no modelo
model.gradient_checkpointing = True
```

### 4. **Limpar Cache da GPU**
```python
import torch
torch.cuda.empty_cache()  # PyTorch
# ou
tf.keras.backend.clear_session()  # TensorFlow
```

### 5. **Monitorar Uso de Mem√≥ria**
```python
# Adicionar ao notebook
import GPUtil
gpus = GPUtil.getGPUs()
for gpu in gpus:
    print(f"GPU {gpu.id}: {gpu.memoryUsed}MB / {gpu.memoryTotal}MB")
```

---

## üìä Estimativa de Tempo de Execu√ß√£o

### Com otimiza√ß√µes:
- **Download Datasets:** 1-2 horas (depende da conex√£o)
- **Extra√ß√£o Baseline CNN:** 2-4 horas
- **Extra√ß√£o ViT Puro:** 3-6 horas
- **Extra√ß√£o ViT + Contrastive:** 4-8 horas
- **Extra√ß√£o ViT + MIM:** **8-16 horas** (mais lento devido a batch size pequeno)
- **Extra√ß√£o ViT + Sparse:** 1-2 horas
- **Classifica√ß√£o:** 1-3 horas
- **Avalia√ß√£o Estat√≠stica:** 10-30 minutos

**Total estimado:** ~20-40 horas (pode ser executado em paralelo onde poss√≠vel)

---

## ‚úÖ Conclus√£o

### **SIM, sua GPU consegue executar o pipeline!**

**Mas com as seguintes ressalvas:**

1. ‚úÖ **Maioria dos componentes:** Funciona bem
2. ‚ö†Ô∏è **ViT + MIM:** Requer batch size muito pequeno (2-4)
3. ‚ö†Ô∏è **Processamento ser√° mais lento** do que em GPUs maiores
4. ‚úÖ **Classifica√ß√£o e an√°lise:** Sem problemas

### Recomenda√ß√µes Finais:

1. **Comece pelos bra√ßos mais leves:**
   - Baseline CNN
   - ViT Puro
   - ViT + Sparse

2. **Deixe ViT + MIM por √∫ltimo** e considere:
   - Processar apenas slices 2D
   - Ou usar dataset 2D alternativo

3. **Monitore o uso de mem√≥ria** durante a execu√ß√£o

4. **Use o MLflow** para rastrear o progresso e n√£o perder resultados

5. **Execute em etapas:** N√£o tente processar tudo de uma vez

---

## üîß Script de Monitoramento

Adicione este c√≥digo aos notebooks para monitorar:

```python
def monitor_gpu():
    """Monitora uso da GPU durante execu√ß√£o."""
    try:
        import GPUtil
        gpus = GPUtil.getGPUs()
        for gpu in gpus:
            print(f"GPU {gpu.name}:")
            print(f"  Mem√≥ria: {gpu.memoryUsed}MB / {gpu.memoryTotal}MB ({gpu.memoryUtil*100:.1f}%)")
            print(f"  Carga: {gpu.load*100:.1f}%")
    except ImportError:
        print("GPUtil n√£o instalado. Instale com: pip install GPUtil")
    except Exception as e:
        print(f"Erro ao monitorar GPU: {e}")

# Chamar periodicamente
monitor_gpu()
```

---

## üìù Checklist de Prepara√ß√£o

Antes de executar:

- [ ] Instalar todas as depend√™ncias
- [ ] Verificar espa√ßo em disco (datasets s√£o grandes)
- [ ] Configurar batch sizes apropriados
- [ ] Preparar ambiente para TensorFlow 1.x (se usar domain_specific_cl)
- [ ] Configurar swap se necess√°rio
- [ ] Iniciar MLflow UI para monitoramento
- [ ] Fazer backup dos resultados periodicamente

**Boa sorte com a execu√ß√£o! üöÄ**

