{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classifica√ß√£o - 5 Bra√ßos Experimentais\n",
        "\n",
        "Este notebook treina classificadores (SVM e SRC) para cada um dos 5 bra√ßos experimentais:\n",
        "\n",
        "1. **Baseline CNN**\n",
        "2. **ViT Puro**\n",
        "3. **ViT + Contrastive**\n",
        "4. **ViT + MIM**\n",
        "5. **ViT + Sparse**\n",
        "\n",
        "## M√©tricas Calculadas\n",
        "\n",
        "- **Acur√°cia**\n",
        "- **F1-Score (macro)**\n",
        "- **Silhouette Score** (para an√°lise de clusters)\n",
        "\n",
        "## Estrutura de Sa√≠da\n",
        "\n",
        "Os resultados ser√£o salvos em:\n",
        "```\n",
        "results/\n",
        "‚îú‚îÄ‚îÄ classifications/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ baseline_cnn_svm_results.json\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ baseline_cnn_src_results.json\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# MLflow para rastreamento de experimentos\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from mlflow import log_metric, log_param, log_artifacts, log_model\n",
        "\n",
        "# Importar SRCClassifier do notebook original\n",
        "# (Voc√™ pode copiar a classe SRCClassifier do SRCClassifier.ipynb aqui ou import√°-la)\n",
        "from sklearn.decomposition import DictionaryLearning\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "# ============================================\n",
        "# DETEC√á√ÉO DE AMBIENTE (COLAB OU LOCAL)\n",
        "# ============================================\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"‚úÖ Google Colab detectado - Drive montado\")\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"‚úÖ Ambiente local detectado\")\n",
        "\n",
        "# Configurar caminhos baseado no ambiente\n",
        "if IN_COLAB:\n",
        "    BASE_DIR = Path(\"/content/drive/MyDrive/Mestrado_TCC\")\n",
        "    FEATURES_DIR = BASE_DIR / \"features\"\n",
        "    RESULTS_DIR = BASE_DIR / \"results\" / \"classifications\"\n",
        "    MLRUNS_DIR = BASE_DIR / \"mlruns\"\n",
        "    # Mudar para diret√≥rio do framework\n",
        "    FRAMEWORK_DIR = BASE_DIR / \"Framework\"\n",
        "    if FRAMEWORK_DIR.exists():\n",
        "        os.chdir(FRAMEWORK_DIR)\n",
        "else:\n",
        "    BASE_DIR = Path(\"../\")\n",
        "    FEATURES_DIR = BASE_DIR / \"features\"\n",
        "    RESULTS_DIR = BASE_DIR / \"results\" / \"classifications\"\n",
        "    MLRUNS_DIR = BASE_DIR / \"mlruns\"\n",
        "\n",
        "# Criar diret√≥rios\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Configura√ß√£o do MLflow\n",
        "MLRUNS_DIR.mkdir(exist_ok=True)\n",
        "mlflow.set_tracking_uri(str(MLRUNS_DIR.absolute()))\n",
        "\n",
        "# Lista dos bra√ßos experimentais\n",
        "EXPERIMENTAL_ARMS = [\n",
        "    \"baseline_cnn\",\n",
        "    \"vit_pure\",\n",
        "    \"vit_contrastive\",\n",
        "    \"vit_mim\",\n",
        "    \"vit_sparse\"\n",
        "]\n",
        "\n",
        "print(f\"\\nüìÅ Diret√≥rios configurados:\")\n",
        "print(f\"   Features: {FEATURES_DIR}\")\n",
        "print(f\"   Resultados: {RESULTS_DIR}\")\n",
        "print(f\"   MLflow: {MLRUNS_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classe SRCClassifier\n",
        "\n",
        "Classe para classifica√ß√£o baseada em Representa√ß√£o Esparsa (adaptada do notebook original).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SRCClassifier:\n",
        "    def __init__(self, n_atoms_per_class=50, alpha=0.001, output_dir='./src_output'):\n",
        "        \"\"\"\n",
        "        Inicializa o classificador SRC.\n",
        "\n",
        "        Args:\n",
        "            n_atoms_per_class (int): N√∫mero de '√°tomos' a serem aprendidos para cada dicion√°rio de classe.\n",
        "            alpha (float): Par√¢metro de regulariza√ß√£o para o LASSO, controla a esparsidade.\n",
        "            output_dir (str): Diret√≥rio para salvar os dicion√°rios e features.\n",
        "        \"\"\"\n",
        "        self.n_atoms_per_class = n_atoms_per_class\n",
        "        self.alpha = alpha\n",
        "        self.dictionaries = {}\n",
        "        self.output_dir = output_dir\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        \"\"\"Aprende um dicion√°rio para cada classe a partir dos dados de treino.\"\"\"\n",
        "        unique_classes = sorted(np.unique(y_train))\n",
        "        for class_label in unique_classes:\n",
        "            X_class = X_train[y_train == class_label]\n",
        "            if len(X_class) == 0:\n",
        "                print(f\"Aviso: Nenhuma amostra de treino para a classe {class_label}. Pulando.\")\n",
        "                continue\n",
        "\n",
        "            print(f\"  Aprendendo dicion√°rio para a classe {class_label}...\")\n",
        "            dict_learner = DictionaryLearning(\n",
        "                n_components=self.n_atoms_per_class,\n",
        "                fit_algorithm='lars',\n",
        "                transform_algorithm='lasso_lars',\n",
        "                random_state=42,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "            dict_learner.fit(X_class)\n",
        "            self.dictionaries[class_label] = dict_learner.components_\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        \"\"\"Classifica amostras baseado no erro de reconstru√ß√£o.\"\"\"\n",
        "        if not self.dictionaries:\n",
        "            raise RuntimeError(\"Os dicion√°rios devem ser aprendidos primeiro. Chame o m√©todo .fit().\")\n",
        "\n",
        "        predictions = []\n",
        "        for x_sample in X_test:\n",
        "            min_error = float('inf')\n",
        "            predicted_class = None\n",
        "\n",
        "            for class_label, dictionary in self.dictionaries.items():\n",
        "                lasso = Lasso(alpha=self.alpha)\n",
        "                lasso.fit(dictionary.T, x_sample)\n",
        "                reconstructed = dictionary.T @ lasso.coef_\n",
        "                error = np.linalg.norm(x_sample - reconstructed)\n",
        "                \n",
        "                if error < min_error:\n",
        "                    min_error = error\n",
        "                    predicted_class = class_label\n",
        "\n",
        "            predictions.append(predicted_class)\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "print(\"Classe SRCClassifier definida!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fun√ß√µes Auxiliares\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualiza√ß√£o no MLflow UI\n",
        "\n",
        "Ap√≥s executar o pipeline, voc√™ pode visualizar os resultados no MLflow UI:\n",
        "\n",
        "```bash\n",
        "mlflow ui --backend-store-uri ../mlruns\n",
        "```\n",
        "\n",
        "Ou se estiver usando o tracking URI configurado:\n",
        "\n",
        "```bash\n",
        "cd ..\n",
        "mlflow ui\n",
        "```\n",
        "\n",
        "Acesse `http://localhost:5000` no navegador para ver todos os experimentos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_features(arm_name, split=\"train\"):\n",
        "    \"\"\"\n",
        "    Carrega features e labels de um bra√ßo experimental.\n",
        "    \n",
        "    Args:\n",
        "        arm_name: Nome do bra√ßo experimental\n",
        "        split: Divis√£o do dataset (\"train\", \"val\", \"test\")\n",
        "    \n",
        "    Returns:\n",
        "        features, labels: Arrays NumPy\n",
        "    \"\"\"\n",
        "    features_path = FEATURES_DIR / arm_name / f\"{split}_features.npy\"\n",
        "    labels_path = FEATURES_DIR / arm_name / f\"{split}_labels.npy\"\n",
        "    \n",
        "    if not features_path.exists() or not labels_path.exists():\n",
        "        print(f\"‚ö†Ô∏è  Arquivos n√£o encontrados para {arm_name} - {split}\")\n",
        "        return None, None\n",
        "    \n",
        "    features = np.load(features_path)\n",
        "    labels = np.load(labels_path)\n",
        "    \n",
        "    print(f\"‚úÖ Carregado {arm_name} - {split}: {features.shape}\")\n",
        "    return features, labels\n",
        "\n",
        "def train_svm_classifier(train_features, train_labels, val_features, val_labels, \n",
        "                         test_features, test_labels, arm_name):\n",
        "    \"\"\"\n",
        "    Treina classificador SVM com Grid Search.\n",
        "    \n",
        "    Returns:\n",
        "        dict: Dicion√°rio com m√©tricas e resultados\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Treinando SVM para {arm_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Normaliza√ß√£o\n",
        "    scaler = StandardScaler()\n",
        "    train_features_scaled = scaler.fit_transform(train_features)\n",
        "    val_features_scaled = scaler.transform(val_features)\n",
        "    test_features_scaled = scaler.transform(test_features)\n",
        "    \n",
        "    # Grid Search\n",
        "    svm = SVC(kernel='rbf', class_weight='balanced', probability=True)\n",
        "    param_grid = {\n",
        "        'C': [0.01, 0.1, 1, 10, 100],\n",
        "        'gamma': ['scale', 'auto', 0.01, 0.1, 1]\n",
        "    }\n",
        "    \n",
        "    print(\"  Executando Grid Search...\")\n",
        "    grid_search = GridSearchCV(\n",
        "        svm,\n",
        "        param_grid,\n",
        "        scoring='f1_macro',\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        verbose=1\n",
        "    )\n",
        "    grid_search.fit(train_features_scaled, train_labels)\n",
        "    \n",
        "    print(f\"  Melhores par√¢metros: {grid_search.best_params_}\")\n",
        "    \n",
        "    # Avalia√ß√£o\n",
        "    best_svm = grid_search.best_estimator_\n",
        "    \n",
        "    # Valida√ß√£o\n",
        "    val_predictions = best_svm.predict(val_features_scaled)\n",
        "    val_accuracy = accuracy_score(val_labels, val_predictions)\n",
        "    val_f1 = f1_score(val_labels, val_predictions, average='macro')\n",
        "    \n",
        "    # Teste\n",
        "    test_predictions = best_svm.predict(test_features_scaled)\n",
        "    test_accuracy = accuracy_score(test_labels, test_predictions)\n",
        "    test_f1 = f1_score(test_labels, test_predictions, average='macro')\n",
        "    \n",
        "    # Silhouette Score\n",
        "    try:\n",
        "        silhouette = silhouette_score(test_features_scaled, test_predictions)\n",
        "    except:\n",
        "        silhouette = None\n",
        "    \n",
        "    results = {\n",
        "        'arm': arm_name,\n",
        "        'classifier': 'SVM',\n",
        "        'best_params': grid_search.best_params_,\n",
        "        'val_accuracy': float(val_accuracy),\n",
        "        'val_f1_macro': float(val_f1),\n",
        "        'test_accuracy': float(test_accuracy),\n",
        "        'test_f1_macro': float(test_f1),\n",
        "        'silhouette_score': float(silhouette) if silhouette is not None else None,\n",
        "        'classification_report': classification_report(test_labels, test_predictions, output_dict=True)\n",
        "    }\n",
        "    \n",
        "    print(f\"  Valida√ß√£o - Acur√°cia: {val_accuracy:.4f}, F1: {val_f1:.4f}\")\n",
        "    print(f\"  Teste - Acur√°cia: {test_accuracy:.4f}, F1: {test_f1:.4f}\")\n",
        "    if silhouette:\n",
        "        print(f\"  Silhouette Score: {silhouette:.4f}\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "def train_src_classifier(train_features, train_labels, val_features, val_labels,\n",
        "                        test_features, test_labels, arm_name, n_atoms=50, alpha=0.1):\n",
        "    \"\"\"\n",
        "    Treina classificador SRC.\n",
        "    \n",
        "    Returns:\n",
        "        dict: Dicion√°rio com m√©tricas e resultados\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Treinando SRC para {arm_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Normaliza√ß√£o\n",
        "    scaler = StandardScaler()\n",
        "    train_features_scaled = scaler.fit_transform(train_features)\n",
        "    val_features_scaled = scaler.transform(val_features)\n",
        "    test_features_scaled = scaler.transform(test_features)\n",
        "    \n",
        "    # Treinar SRC\n",
        "    print(\"  Aprendendo dicion√°rios...\")\n",
        "    src = SRCClassifier(n_atoms_per_class=n_atoms, alpha=alpha)\n",
        "    src.fit(train_features_scaled, train_labels)\n",
        "    \n",
        "    # Avalia√ß√£o\n",
        "    print(\"  Fazendo predi√ß√µes...\")\n",
        "    val_predictions = src.predict(val_features_scaled)\n",
        "    test_predictions = src.predict(test_features_scaled)\n",
        "    \n",
        "    val_accuracy = accuracy_score(val_labels, val_predictions)\n",
        "    val_f1 = f1_score(val_labels, val_predictions, average='macro')\n",
        "    test_accuracy = accuracy_score(test_labels, test_predictions)\n",
        "    test_f1 = f1_score(test_labels, test_predictions, average='macro')\n",
        "    \n",
        "    # Silhouette Score\n",
        "    try:\n",
        "        silhouette = silhouette_score(test_features_scaled, test_predictions)\n",
        "    except:\n",
        "        silhouette = None\n",
        "    \n",
        "    results = {\n",
        "        'arm': arm_name,\n",
        "        'classifier': 'SRC',\n",
        "        'n_atoms_per_class': n_atoms,\n",
        "        'alpha': alpha,\n",
        "        'val_accuracy': float(val_accuracy),\n",
        "        'val_f1_macro': float(val_f1),\n",
        "        'test_accuracy': float(test_accuracy),\n",
        "        'test_f1_macro': float(test_f1),\n",
        "        'silhouette_score': float(silhouette) if silhouette is not None else None,\n",
        "        'classification_report': classification_report(test_labels, test_predictions, output_dict=True)\n",
        "    }\n",
        "    \n",
        "    print(f\"  Valida√ß√£o - Acur√°cia: {val_accuracy:.4f}, F1: {val_f1:.4f}\")\n",
        "    print(f\"  Teste - Acur√°cia: {test_accuracy:.4f}, F1: {test_f1:.4f}\")\n",
        "    if silhouette:\n",
        "        print(f\"  Silhouette Score: {silhouette:.4f}\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "print(\"Fun√ß√µes auxiliares criadas!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline de Classifica√ß√£o Completo\n",
        "\n",
        "Executa classifica√ß√£o para todos os bra√ßos experimentais.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_classification_pipeline():\n",
        "    \"\"\"\n",
        "    Executa o pipeline completo de classifica√ß√£o para todos os bra√ßos experimentais.\n",
        "    \"\"\"\n",
        "    all_results = []\n",
        "    \n",
        "    for arm in EXPERIMENTAL_ARMS:\n",
        "        print(f\"\\n{'#'*60}\")\n",
        "        print(f\"Processando: {arm}\")\n",
        "        print(f\"{'#'*60}\")\n",
        "        \n",
        "        # Carregar features\n",
        "        train_features, train_labels = load_features(arm, \"train\")\n",
        "        val_features, val_labels = load_features(arm, \"val\")\n",
        "        test_features, test_labels = load_features(arm, \"test\")\n",
        "        \n",
        "        if train_features is None:\n",
        "            print(f\"‚ö†Ô∏è  Pulando {arm} - features n√£o encontradas\")\n",
        "            continue\n",
        "        \n",
        "        # Treinar SVM\n",
        "        try:\n",
        "            svm_results = train_svm_classifier(\n",
        "                train_features, train_labels,\n",
        "                val_features, val_labels,\n",
        "                test_features, test_labels,\n",
        "                arm\n",
        "            )\n",
        "            all_results.append(svm_results)\n",
        "            \n",
        "            # Salvar resultados SVM\n",
        "            output_path = RESULTS_DIR / f\"{arm}_svm_results.json\"\n",
        "            with open(output_path, 'w') as f:\n",
        "                json.dump(svm_results, f, indent=2)\n",
        "            print(f\"‚úÖ Resultados SVM salvos em: {output_path}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao treinar SVM para {arm}: {e}\")\n",
        "        \n",
        "        # Treinar SRC\n",
        "        try:\n",
        "            src_results = train_src_classifier(\n",
        "                train_features, train_labels,\n",
        "                val_features, val_labels,\n",
        "                test_features, test_labels,\n",
        "                arm,\n",
        "                n_atoms=50,\n",
        "                alpha=0.1\n",
        "            )\n",
        "            all_results.append(src_results)\n",
        "            \n",
        "            # Salvar resultados SRC\n",
        "            output_path = RESULTS_DIR / f\"{arm}_src_results.json\"\n",
        "            with open(output_path, 'w') as f:\n",
        "                json.dump(src_results, f, indent=2)\n",
        "            print(f\"‚úÖ Resultados SRC salvos em: {output_path}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao treinar SRC para {arm}: {e}\")\n",
        "    \n",
        "    # Criar tabela resumo\n",
        "    summary_data = []\n",
        "    for result in all_results:\n",
        "        summary_data.append({\n",
        "            'Arm': result['arm'],\n",
        "            'Classifier': result['classifier'],\n",
        "            'Val Accuracy': f\"{result['val_accuracy']:.4f}\",\n",
        "            'Val F1': f\"{result['val_f1_macro']:.4f}\",\n",
        "            'Test Accuracy': f\"{result['test_accuracy']:.4f}\",\n",
        "            'Test F1': f\"{result['test_f1_macro']:.4f}\",\n",
        "            'Silhouette': f\"{result['silhouette_score']:.4f}\" if result['silhouette_score'] else \"N/A\"\n",
        "        })\n",
        "    \n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "    summary_path = RESULTS_DIR / \"summary_results.csv\"\n",
        "    summary_df.to_csv(summary_path, index=False)\n",
        "    print(f\"\\n‚úÖ Tabela resumo salva em: {summary_path}\")\n",
        "    print(\"\\n\" + summary_df.to_string())\n",
        "    \n",
        "    return all_results, summary_df\n",
        "\n",
        "# Executar pipeline\n",
        "# results, summary = run_classification_pipeline()\n",
        "print(\"Pipeline de classifica√ß√£o preparado. Descomente a √∫ltima linha para executar.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
