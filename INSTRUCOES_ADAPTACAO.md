# ğŸ“ InstruÃ§Ãµes para AdaptaÃ§Ã£o dos Notebooks

## âœ… O que jÃ¡ foi criado

1. **PLANO_ADAPTACAO.md** - Plano completo do pipeline adaptado
2. **01_Download_Datasets.ipynb** - Notebook para download e preparaÃ§Ã£o dos datasets
3. **02_Feature_Extraction.ipynb** - Notebook base para extraÃ§Ã£o de features (estrutura inicial criada)

## ğŸ”§ PrÃ³ximos Passos

### 1. Completar o Notebook 02_Feature_Extraction.ipynb

VocÃª precisa adicionar as seguintes cÃ©lulas ao notebook:

#### CÃ©lula: FunÃ§Ãµes para carregar dados mÃ©dicos
```python
import nibabel as nib

def load_medical_image(filepath, normalize=True):
    """Carrega imagem mÃ©dica (2D slice de volume 3D ou imagem 2D)."""
    filepath = Path(filepath)
    
    if filepath.suffix == '.gz' or '.nii' in filepath.name:
        img = nib.load(str(filepath))
        data = img.get_fdata()
        if len(data.shape) == 3:
            data = data[:, :, data.shape[2] // 2]  # Slice central
        if normalize:
            data = (data - data.min()) / (data.max() - data.min() + 1e-8) * 255
        if len(data.shape) == 2:
            data = np.stack([data, data, data], axis=-1)
        return tf.cast(data, tf.uint8)
    else:
        image = tf.io.read_file(str(filepath))
        if filepath.suffix.lower() in ['.jpg', '.jpeg']:
            image = tf.image.decode_jpeg(image, channels=3)
        return image
```

#### CÃ©lula: Extrator Baseline CNN
```python
def build_baseline_cnn_extractor(input_size=224):
    """ConstrÃ³i extrator usando ResNet50 prÃ©-treinado."""
    base_model = ResNet50(weights='imagenet', include_top=False, 
                          input_shape=(input_size, input_size, 3))
    base_model.trainable = False
    
    inputs = layers.Input(shape=(input_size, input_size, 3), dtype=tf.float32)
    x = tf.keras.applications.resnet50.preprocess_input(inputs)
    x = base_model(x, training=False)
    x = layers.GlobalAveragePooling2D()(x)
    
    return models.Model(inputs=inputs, outputs=x)
```

#### CÃ©lula: IntegraÃ§Ã£o com domain_specific_cl
```python
def build_vit_contrastive_extractor(repo_path="../repositories/domain_specific_cl"):
    """
    Integra com o repositÃ³rio domain_specific_cl.
    
    Passos:
    1. Clone o repositÃ³rio: git clone https://github.com/krishnabits001/domain_specific_cl
    2. Instale as dependÃªncias conforme o README do repositÃ³rio
    3. Carregue o modelo prÃ©-treinado
    4. Adapte esta funÃ§Ã£o para extrair features
    """
    sys.path.append(str(Path(repo_path).absolute()))
    
    # TODO: Adaptar conforme a estrutura do repositÃ³rio
    # Exemplo:
    # from models import YourContrastiveModel
    # model = YourContrastiveModel.load_from_checkpoint(checkpoint_path)
    # return model
    
    # Por enquanto, fallback para ViT puro
    return build_vit_pure_extractor()
```

#### CÃ©lula: IntegraÃ§Ã£o com MIM-Med3D
```python
def build_vit_mim_extractor(repo_path="../repositories/MIM-Med3D"):
    """
    Integra com o repositÃ³rio MIM-Med3D.
    
    Passos:
    1. Clone o repositÃ³rio: git clone https://github.com/chenz53/MIM-Med3D
    2. Instale as dependÃªncias conforme o README do repositÃ³rio
    3. Carregue o modelo prÃ©-treinado
    4. Adapte esta funÃ§Ã£o para extrair features
    """
    sys.path.append(str(Path(repo_path).absolute()))
    
    # TODO: Adaptar conforme a estrutura do repositÃ³rio
    # Exemplo:
    # from models import MIMViT
    # model = MIMViT.load_from_checkpoint(checkpoint_path)
    # return model
    
    # Por enquanto, fallback para ViT puro
    return build_vit_pure_extractor()
```

#### CÃ©lula: AplicaÃ§Ã£o de Esparsidade
```python
from sklearn.decomposition import DictionaryLearning

def apply_sparsity_to_features(features, n_atoms=50, alpha=0.1):
    """Aplica esparsidade nas features usando Dictionary Learning."""
    dict_learner = DictionaryLearning(
        n_components=n_atoms,
        alpha=alpha,
        fit_algorithm='lars',
        transform_algorithm='lasso_lars',
        n_jobs=-1
    )
    sparse_features = dict_learner.fit_transform(features)
    return sparse_features, dict_learner
```

### 2. Adaptar o Notebook 03_Classification.ipynb

Baseado nos notebooks `SVMClassifier.ipynb` e `SRCClassifier.ipynb`, criar um notebook que:

1. Carrega features de todos os 5 braÃ§os experimentais
2. Treina classificadores (SVM e SRC) para cada braÃ§o
3. Calcula mÃ©tricas (AcurÃ¡cia, F1, Silhouette) para cada combinaÃ§Ã£o
4. Salva resultados em estrutura organizada

**Estrutura esperada:**
```python
# Para cada braÃ§o experimental
for arm in ["baseline_cnn", "vit_pure", "vit_contrastive", "vit_mim", "vit_sparse"]:
    # Carregar features
    train_features = np.load(f"../features/{arm}/train_features.npy")
    train_labels = np.load(f"../features/{arm}/train_labels.npy")
    # ... val e test
    
    # Treinar SVM
    svm_results = train_svm_classifier(train_features, train_labels, ...)
    
    # Treinar SRC
    src_results = train_src_classifier(train_features, train_labels, ...)
    
    # Salvar resultados
    save_results(arm, svm_results, src_results)
```

### 3. Adaptar o Notebook 04_Avaliacao_Estatistica.ipynb

Baseado no notebook `AvaliaÃ§Ã£o_estatitisca.ipynb`, adaptar para:

1. Carregar resultados de todos os 5 braÃ§os experimentais
2. Executar Teste de Friedman
3. Executar pÃ³s-testes (Nemenyi, Conover, Bonferroni)
4. Gerar visualizaÃ§Ãµes comparativas

**Estrutura esperada:**
```python
# Carregar F1-scores de todos os braÃ§os
f1_scores = {
    "Baseline CNN": [...],
    "ViT Puro": [...],
    "ViT + Contrastive": [...],
    "ViT + MIM": [...],
    "ViT + Sparse": [...]
}

# Executar anÃ¡lise estatÃ­stica
analysis = StatisticalAnalysis(f1_scores, alpha=0.05)
analysis.friedman_test()
analysis.nemenyi_test()
# ... outros testes
```

### 4. Criar Notebook 05_Visualizacao_XAI.ipynb (Opcional)

Este notebook deve:

1. Gerar mapas de atenÃ§Ã£o para os 3 tipos de ViT
2. Visualizar clusters usando t-SNE
3. Comparar representaÃ§Ãµes esparsas vs. outras

## ğŸ”— IntegraÃ§Ã£o com RepositÃ³rios

### RepositÃ³rio 1: domain_specific_cl

**URL:** https://github.com/krishnabits001/domain_specific_cl

**Passos para integraÃ§Ã£o:**
1. Clone o repositÃ³rio:
   ```bash
   cd ../repositories
   git clone https://github.com/krishnabits001/domain_specific_cl
   ```

2. Instale dependÃªncias conforme o README do repositÃ³rio

3. Baixe o modelo prÃ©-treinado (se disponÃ­vel)

4. Adapte a funÃ§Ã£o `build_vit_contrastive_extractor()` para carregar o modelo

5. Use o modelo para extrair features do dataset ACDC

### RepositÃ³rio 2: MIM-Med3D

**URL:** https://github.com/chenz53/MIM-Med3D

**Passos para integraÃ§Ã£o:**
1. Clone o repositÃ³rio:
   ```bash
   cd ../repositories
   git clone https://github.com/chenz53/MIM-Med3D
   ```

2. Instale dependÃªncias conforme o README do repositÃ³rio

3. Baixe o modelo prÃ©-treinado (se disponÃ­vel)

4. Adapte a funÃ§Ã£o `build_vit_mim_extractor()` para carregar o modelo

5. Use o modelo para extrair features do dataset BraTS

## ğŸ“Š Estrutura de Dados Esperada

### Features
```
features/
â”œâ”€â”€ baseline_cnn/
â”‚   â”œâ”€â”€ train_features.npy
â”‚   â”œâ”€â”€ train_labels.npy
â”‚   â”œâ”€â”€ val_features.npy
â”‚   â”œâ”€â”€ val_labels.npy
â”‚   â”œâ”€â”€ test_features.npy
â”‚   â””â”€â”€ test_labels.npy
â”œâ”€â”€ vit_pure/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ vit_contrastive/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ vit_mim/
â”‚   â””â”€â”€ ...
â””â”€â”€ vit_sparse/
    â””â”€â”€ ...
```

### Resultados
```
results/
â”œâ”€â”€ classifications/
â”‚   â”œâ”€â”€ baseline_cnn_svm_results.json
â”‚   â”œâ”€â”€ baseline_cnn_src_results.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ evaluations/
â”‚   â”œâ”€â”€ friedman_test_results.json
â”‚   â””â”€â”€ posthoc_test_results.json
â””â”€â”€ visualizations/
    â”œâ”€â”€ attention_maps/
    â””â”€â”€ tsne_plots/
```

## ğŸš€ Ordem de ExecuÃ§Ã£o

1. **01_Download_Datasets.ipynb** - Baixar e preparar datasets
2. **02_Feature_Extraction.ipynb** - Extrair features para todos os braÃ§os
3. **03_Classification.ipynb** - Treinar classificadores
4. **04_Avaliacao_Estatistica.ipynb** - Avaliar resultados estatisticamente
5. **05_Visualizacao_XAI.ipynb** (opcional) - VisualizaÃ§Ãµes e XAI

## ğŸ“ Notas Importantes

- Todos os notebooks devem ser modulares e reutilizÃ¡veis
- Salvar resultados intermediÃ¡rios para evitar reprocessamento
- Documentar parÃ¢metros e configuraÃ§Ãµes em cada notebook
- Garantir compatibilidade entre etapas do pipeline
- Adaptar funÃ§Ãµes de carregamento de dados para cada dataset especÃ­fico (ACDC vs BraTS)

## ğŸ” VerificaÃ§Ã£o

ApÃ³s completar a adaptaÃ§Ã£o, verifique:

- [ ] Todos os 5 braÃ§os experimentais estÃ£o implementados
- [ ] Features sÃ£o extraÃ­das corretamente para cada braÃ§o
- [ ] Classificadores sÃ£o treinados para todos os braÃ§os
- [ ] AvaliaÃ§Ã£o estatÃ­stica compara todos os braÃ§os
- [ ] Resultados sÃ£o salvos em estrutura organizada
- [ ] IntegraÃ§Ã£o com repositÃ³rios externos funciona

